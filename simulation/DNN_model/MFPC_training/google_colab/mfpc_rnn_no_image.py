# -*- coding: utf-8 -*-
"""MFPC_RNN_no_image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VdhuqL18F9y-ysQ6F4HG0OBjaL5Npdmb
"""

# Unzip data
!unzip "/content/drive/My Drive/Masters Year/data_mfpc/processed_002.zip"

import cv2
import math
import random
import matplotlib
import numpy as np
import pandas as pd
from PIL import Image
import tensorflow as tf
from tensorflow import keras
import matplotlib.image as mpimg
from matplotlib import pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping
np.random.seed(1000)
from sklearn import preprocessing
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet import preprocess_input

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import load_model

import cv2
import matplotlib
import numpy as np
import pandas as pd
from PIL import Image
import tensorflow as tf
from tensorflow import keras
import matplotlib.image as mpimg
from matplotlib import pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping
np.random.seed(1000)
from sklearn import preprocessing
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG19
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet import preprocess_input

################################## Hyper Parameters ##################################################################
# data_location =   # "/home/wmandil/MFPC/datasets/data_set_005/"
model_location =  "/content/drive/My Drive/Masters Year/data_mfpc/custom_model_no_image_022_intermediate.h5" # "/home/wmandil/MFPC/datasets/trained_models/custom_model_no_image_022_intermediate.h5"
validation_set_size = 1500
no_of_cameras = 8 + 1
timeWindow = 4
trajectory_length = 1
data_set_length = 11000
scale_up_value = 100000
single_sample_length = 199
train_size__ = 0.8
batch_size = 60  ##  32 breaks system as test data length not divisible by 32 - 30 does work too

################################# Robot vel and pos straw inputs + strawberry label ##################################
robot_pos_trajectory_input_shuffled = pd.read_csv('/content/processed_002/robot_pos_traj_input_data_set_shuffled_scaled100000_no_standardisation', header=None)
robot_vel_trajectory_input_shuffled = pd.read_csv('/content/processed_002/robot_vel_traj_input_data_set_shuffled_scaled100000_no_standardisation', header=None)
strawberry_state_input_shuffled = pd.read_csv('/content/processed_002/straw_input_data_set_shuffled_scaled100000_no_standardisation', header=None)
strawberry_state_label_shuffled = pd.read_csv('/content/processed_002/straw_label_data_set_shuffled_scaled100000_no_standardisation', header=None)
################################## Standardization for Robot States ###################################################################
robot_pos_trajectory_input_shuffled_names = robot_pos_trajectory_input_shuffled.columns
scaler = preprocessing.StandardScaler()
myScaler = scaler.fit(robot_pos_trajectory_input_shuffled)
robot_pos_trajectory_input_shuffled = myScaler.transform(robot_pos_trajectory_input_shuffled)
robot_pos_trajectory_input_shuffled = pd.DataFrame(robot_pos_trajectory_input_shuffled, columns=robot_pos_trajectory_input_shuffled_names)
print(robot_pos_trajectory_input_shuffled.shape)

robot_vel_trajectory_input_shuffled_names = robot_vel_trajectory_input_shuffled.columns
scaler = preprocessing.StandardScaler()
myScaler = scaler.fit(robot_vel_trajectory_input_shuffled)
robot_vel_trajectory_input_shuffled = myScaler.transform(robot_vel_trajectory_input_shuffled)
robot_vel_trajectory_input_shuffled = pd.DataFrame(robot_vel_trajectory_input_shuffled, columns=robot_vel_trajectory_input_shuffled_names)
print(robot_vel_trajectory_input_shuffled.shape)


strawberry_state_input_shuffled_names = strawberry_state_input_shuffled.columns
scaler = preprocessing.StandardScaler()
myScaler = scaler.fit(strawberry_state_input_shuffled)
strawberry_state_input_shuffled = myScaler.transform(strawberry_state_input_shuffled)
strawberry_state_input_shuffled = pd.DataFrame(strawberry_state_input_shuffled, columns=strawberry_state_input_shuffled_names)
print(strawberry_state_input_shuffled.shape)

################################## convert data_frame to list ###################################################################
robot_pos_trajectory_input = robot_pos_trajectory_input_shuffled.values.tolist()
robot_vel_trajectory_input = robot_vel_trajectory_input_shuffled.values.tolist()
strawberry_state_input = strawberry_state_input_shuffled.values.tolist()
strawberry_state_label = strawberry_state_label_shuffled.values.tolist()

################################## split data test and train ###################################################################
dataset_length = len(robot_vel_trajectory_input_shuffled)
robot_pos_trajectory_input_train = tf.convert_to_tensor(robot_pos_trajectory_input[0:int(dataset_length*0.75)])
robot_pos_trajectory_input_test = tf.convert_to_tensor(robot_pos_trajectory_input[int(dataset_length*0.75):dataset_length])
robot_vel_trajectory_input_train = tf.convert_to_tensor(robot_vel_trajectory_input[0:int(dataset_length*0.75)])
robot_vel_trajectory_input_test = tf.convert_to_tensor(robot_vel_trajectory_input[int(dataset_length*0.75):dataset_length])
strawberry_state_input_train = tf.convert_to_tensor(strawberry_state_input[0:int(dataset_length*0.75)])
strawberry_state_input_test = tf.convert_to_tensor(strawberry_state_input[int(dataset_length*0.75):dataset_length])
strawberry_state_label_train = tf.convert_to_tensor(strawberry_state_label[0:int(dataset_length*0.75)])
strawberry_state_label_test = tf.convert_to_tensor(strawberry_state_label[int(dataset_length*0.75):dataset_length])
print(strawberry_state_input_train.shape)

################################## load intermediate model ###################################################################
intermediate_layer_model = load_model(model_location)
intermediate_output_train = intermediate_layer_model.predict([strawberry_state_input_train, robot_pos_trajectory_input_train, robot_vel_trajectory_input_train])
intermediate_output_test = intermediate_layer_model.predict([strawberry_state_input_test, robot_pos_trajectory_input_test, robot_vel_trajectory_input_test])
print(intermediate_output_train.shape)

validation_set_size = 1500

train_set = intermediate_output_train[0:intermediate_output_train.shape[0]-validation_set_size , : ]
validation_set = intermediate_output_train[intermediate_output_train.shape[0]-validation_set_size: , : ]
test_set = intermediate_output_test[: , :]

timeWindow = 4

train = keras.preprocessing.sequence.TimeseriesGenerator(train_set, train_set, length=timeWindow, sampling_rate=1, stride=1, batch_size=1)
validation = keras.preprocessing.sequence.TimeseriesGenerator(validation_set, validation_set, length=timeWindow, sampling_rate=1, stride=1, batch_size=1)
test = keras.preprocessing.sequence.TimeseriesGenerator(test_set, test_set, length=timeWindow, sampling_rate=1, stride=1, batch_size=1)

train[0][0].shape

print("train_set shape: {}".format(train_set.shape))

train_matrix = np.zeros((train_set.shape[0]-timeWindow, timeWindow, 64))
for i in range(timeWindow,train_set.shape[0]):
  train_matrix[i-timeWindow, : , : ] = train[i-timeWindow][0][0]

validation_matrix = np.zeros((validation_set.shape[0]-timeWindow, timeWindow, 64))
for i in range(timeWindow,validation_set.shape[0]):
  validation_matrix[i-timeWindow, : , : ] = validation[i-timeWindow][0][0]

test_matrix = np.zeros((test_set.shape[0]-timeWindow, timeWindow, 64))
for i in range(timeWindow,test_set.shape[0]):
  test_matrix[i-timeWindow, : , : ] = test[i-timeWindow][0][0]


output_train_matrix = np.zeros((train_set.shape[0]-timeWindow, 9))
for i in range(timeWindow,train_set.shape[0]):
  output_train_matrix[i-timeWindow , :] = strawberry_state_label_train[i-timeWindow:(i-timeWindow+1)]

output_validation_matrix = np.zeros((validation_set.shape[0]-timeWindow, 9))
for i in range(timeWindow,validation_set.shape[0]):
  output_validation_matrix[i-timeWindow, : ] = strawberry_state_label_train[(intermediate_output_train.shape[0] - validation_set_size + i - timeWindow):(intermediate_output_train.shape[0] - validation_set_size + i - timeWindow)+1]

output_test_matrix = np.zeros((test_set.shape[0]-timeWindow, 9))
for i in range(timeWindow,test_set.shape[0]):
  output_test_matrix[i - timeWindow,:] = strawberry_state_label_test[(i - timeWindow):(i - timeWindow)+1]

print("output_test_matrix: {}".format(output_test_matrix.shape))

monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True)
GRU_Model = keras.models.Sequential()
GRU_Model.add(keras.layers.GRU(150, return_sequences=True, input_shape=(timeWindow,64 )))
GRU_Model.add(keras.layers.GRU(100, input_shape=(timeWindow,64 )))
GRU_Model.add(keras.layers.Dense(50))
GRU_Model.add(keras.layers.Dense(40))
GRU_Model.add(keras.layers.Dense(9,activation="linear"))
GRU_Model.compile(loss='mae', optimizer=keras.optimizers.Adam(), metrics=['mse','accuracy'])
GRU_Model.fit(train_matrix ,output_train_matrix, callbacks=[monitor], epochs=40, validation_data=(validation_matrix, output_validation_matrix),verbose=1)
score= GRU_Model.evaluate(test_matrix, output_test_matrix) 

test_predict_gru = GRU_Model.predict(test_matrix)

err_GRU_Model= test_predict_gru - output_test_matrix
Gru_err_mean = np.mean(abs(err_GRU_Model))
a = np.where(err_GRU_Model > 0.01)
a = np.asarray(list(zip(*a)))
print("number of err elements higher than 0.01")
print(a.shape)

GRU_Model.save('/content/drive/My Drive/Masters Year/data_mfpc/no_image_GRU_001.h5')

GRU_Model.summary()